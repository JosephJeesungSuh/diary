LLMS = [
    {
        "model_name": "gemini-1.5-flash",
        "api_provider": "google",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "gemini-2.0-flash",
        "api_provider": "google",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "gemini-2.5-flash",
        "api_provider": "google",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "gpt-4o",
        "api_provider": "openai",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "gpt-4o-mini",
        "api_provider": "openai",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "o3-mini",
        "api_provider": "openai",
        "is_instruct": True,
        "is_reasoning": True,
    },
    {
        "model_name": "deepseek-chat",
        "api_provider": "deepseek",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "deepseek-reasoner",
        "api_provider": "deepseek",
        "is_instruct": True,
        "is_reasoning": True,
    },
    {
        "model_name": "mistralai/Mistral-Small-24B-Base-2501",
        "api_provider": "localhost",
        "is_instruct": False,
        "is_reasoning": False,
    },
    {
        "model_name": "meta-llama/Llama-3.1-70B-Instruct",
        "api_provider": "localhost",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "api_provider": "localhost",
        "is_instruct": True,
        "is_reasoning": False,
    },
    {
        "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "api_provider": "localhost",
        "is_instruct": True,
        "is_reasoning": True,
    },
    {
        "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "api_provider": "localhost",
        "is_instruct": True,
        "is_reasoning": True,
    },
    {
        "model_name": "meta-llama/Llama-3.1-8B-Instruct",
        "api_provider": "localhost",
        "is_instruct": True,
        "is_reasoning": False,
    }
]
